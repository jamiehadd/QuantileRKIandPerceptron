{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "givJsqPV-o4Y"
      },
      "source": [
        "# Necessary installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d_TGWg8yP6f"
      },
      "outputs": [],
      "source": [
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install ucimlrepo\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6q1nOvwyP6g"
      },
      "source": [
        "# Import Statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wU-nVOklyP6g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "import random\n",
        "import time  # Importing time module for tracking elapsed time\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMwuoX2oyP6h"
      },
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/jamiehadd/QuantileRKIandPerceptron/refs/heads/main/functions_QRK.py'\n",
        "!wget --no-cache --backups=1 {url}\n",
        "from functions_QRK import perceptronModified"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxjuYaZKf_ek"
      },
      "source": [
        "# Sampled Indices: Timing them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbC55HoZLyMH"
      },
      "source": [
        "# Real World Data Set: Banknote Authentication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIhx1m7gNnMQ"
      },
      "outputs": [],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Fetch the Banknote Authentication Dataset\n",
        "banknote_data = fetch_ucirepo(id=267)\n",
        "\n",
        "# Extract features and target\n",
        "X = banknote_data.data.features # Features (variance, skewness, etc.)\n",
        "y = banknote_data.data.targets\n",
        "\n",
        "X = X.values\n",
        "y = y.values\n",
        "y = y.ravel()\n",
        "y = 2*y-1 # to make it fit our algorithm\n",
        "\n",
        "# Scale the features (standardize them)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled_T = X_scaled.T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h3DukxAyP6i"
      },
      "source": [
        "# We set the SVM baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCLemHrAyP6i"
      },
      "outputs": [],
      "source": [
        "# We will train on the full dataset without any random split\n",
        "svm = SVC(kernel='linear')  # Linear kernel for decision boundary\n",
        "svm.fit(X_scaled, y)  # Train on the full dataset to get linear truth labels\n",
        "\n",
        "# Predict the labels using the trained model\n",
        "y_pred = svm.predict(X_scaled)\n",
        "\n",
        "# Evaluate the predictions by comparing with the true labels\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "report = classification_report(y, y_pred)\n",
        "\n",
        "print(f\"Accuracy of SVM classifier with linear kernel: {accuracy * 100:.2f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "incorrectly_classified = np.where(y != y_pred)[0]\n",
        "misclassified = 1 - accuracy # just to store the values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS3bmwFEyP6j"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Code to check how balanced is the dataset.\n",
        "'''\n",
        "\n",
        "count_ones = np.sum(y == 1)\n",
        "count_minus_ones = np.sum(y == -1)\n",
        "\n",
        "print(f\"Number of 1s in y: {count_ones}\")\n",
        "print(f\"Number of -1s in y: {count_minus_ones}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdfl0bxAa9Qy"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Setting the parameters for the algorithm\n",
        "'''\n",
        "\n",
        "numDataPoints = X_scaled_T.shape[1]\n",
        "numMislabelled = len(incorrectly_classified)\n",
        "correct_labels = y_pred\n",
        "data = X_scaled_T\n",
        "labels = y\n",
        "t = numDataPoints\n",
        "N = 5000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vPLO-xJViG_"
      },
      "outputs": [],
      "source": [
        "quantile_list = [0.85, 0.9, 0.95, 0.97]\n",
        "residual_list = []  # Dictionary to store residuals for each quantile\n",
        "nTrials = 10 # how many rounds of averaging we wish to do\n",
        "\n",
        "for q in quantile_list:\n",
        "  intermediateResiduals = []\n",
        "  for i in range(nTrials):\n",
        "      x, residuals, _ = perceptronModified(data, labels, q, numDataPoints, N, correct_labels, numMislabelled, numDataPoints)\n",
        "      intermediateResiduals.append(residuals)\n",
        "\n",
        "  intermediateResiduals = np.mean(intermediateResiduals, axis = 0)\n",
        "  residual_list.append(intermediateResiduals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jTdZ3Q1yP6k"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "line_styles = ['-', '--', ':', '-.']\n",
        "\n",
        "# Create a plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for idx, residuals in enumerate(residual_list):\n",
        "    # Ensure x matches the length of residuals (assuming iteration count is equal to len(residuals))\n",
        "    x = np.arange(len(residuals))\n",
        "\n",
        "    plt.plot(x, residuals, label=f'{quantile_list[idx]}', linestyle=line_styles[idx], linewidth=3)\n",
        "\n",
        "\n",
        "plt.xlim(0, N)\n",
        "plt.ylim(20, 80)\n",
        "plt.yticks(np.arange(0, 110, 10), fontsize=14)\n",
        "plt.xticks(fontsize=14)\n",
        "plt.xlabel('Iterations', fontsize=16)\n",
        "plt.ylabel('Percent of Misclassified Inequalities', fontsize=16)\n",
        "plt.legend(title='Quantile', fontsize=14, title_fontsize=16)\n",
        "plt.grid(True)\n",
        "plt.savefig('banknotes_data_final_plot.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h46QlrYyP6k"
      },
      "outputs": [],
      "source": [
        "sampled_indices_list = [450, 900, 1372]\n",
        "line_styles = ['-', '--', ':']\n",
        "markers = ['o', 's', '*']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMrwBHKnyP6k"
      },
      "outputs": [],
      "source": [
        "residual_list = []\n",
        "residual_errors = []\n",
        "residual_dict = {}\n",
        "error_dict = {}\n",
        "\n",
        "for t in sampled_indices_list:\n",
        "    residual_list_i = []\n",
        "    residual_errors_i = []\n",
        "    for i in range(nTrials):\n",
        "        x, residuals, residuals_time = perceptronModified(data, labels, 0.97, t, N, correct_labels, numMislabelled, numDataPoints)\n",
        "        residual_list_i.append(residuals_time)\n",
        "        residual_errors_i.append(residuals)\n",
        "\n",
        "    avg_residual_time = np.mean(residual_list_i, axis=0)\n",
        "    avg_residual_error = np.mean(residual_errors_i, axis=0)\n",
        "    residual_list.append(avg_residual_time)\n",
        "    residual_errors.append(avg_residual_error)\n",
        "    residual_dict[t] = avg_residual_time\n",
        "    error_dict[t] = avg_residual_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "822IWVFuyP6k"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for idx, t in enumerate(sampled_indices_list):\n",
        "    x_values = residual_dict[t]\n",
        "    y_values = error_dict[t]\n",
        "\n",
        "    line_style = line_styles[idx % len(line_styles)]\n",
        "    marker = markers[idx % len(markers)]\n",
        "\n",
        "    plt.plot(x_values, y_values, label=f'{t}', linestyle=line_style, marker=marker, linewidth=3)\n",
        "\n",
        "plt.xlabel('Time (in seconds)', fontsize=16)\n",
        "plt.ylabel('Percent of Misclassified Inequalities', fontsize=16)\n",
        "plt.legend(title='Number Sampled Indices', fontsize=14, title_fontsize=16, loc='upper right')\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.grid(True, which='both', axis='both')\n",
        "plt.xlim(left=0)\n",
        "plt.ylim(bottom=0)\n",
        "\n",
        "# Save the figure as a PNG file\n",
        "plt.savefig('time_sampled_indices_q_equals_0.97_5000_banknotes_final_iterations.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b6hJb8yrMe4"
      },
      "source": [
        "# Occupancy dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTtvMw36lple"
      },
      "outputs": [],
      "source": [
        "occupancy_detection = fetch_ucirepo(id=357)\n",
        "occupancy_detection.data.features = occupancy_detection.data.features.drop(columns=['date']) # Drop the 'date' column\n",
        "# Convert numeric columns to the correct data type using .loc\n",
        "occupancy_detection.data.features.loc[:, 'Temperature'] = pd.to_numeric(occupancy_detection.data.features['Temperature'], errors='coerce')\n",
        "occupancy_detection.data.features.loc[:, 'Humidity'] = pd.to_numeric(occupancy_detection.data.features['Humidity'], errors='coerce')\n",
        "occupancy_detection.data.features.loc[:, 'Light'] = pd.to_numeric(occupancy_detection.data.features['Light'], errors='coerce')\n",
        "occupancy_detection.data.features.loc[:, 'CO2'] = pd.to_numeric(occupancy_detection.data.features['CO2'], errors='coerce')\n",
        "occupancy_detection.data.features.loc[:, 'HumidityRatio'] = pd.to_numeric(occupancy_detection.data.features['HumidityRatio'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "471D98LNy49q"
      },
      "outputs": [],
      "source": [
        "X = occupancy_detection.data.features\n",
        "y = occupancy_detection.data.targets\n",
        "# Drop NaN rows\n",
        "X_clean = X.drop(index=[8143, 10809])\n",
        "y_clean = y.drop(index=[8143, 10809])\n",
        "\n",
        "# Convert y_clean to NumPy and transform it into {-1, 1}\n",
        "y_clean = y_clean.values.ravel()\n",
        "y_clean = 2 * y_clean - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFe9FKUGyP6k"
      },
      "source": [
        "# We set the SVM baseline again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aZ19az-yP6k"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_clean)\n",
        "X_scaled_T = X_scaled.T\n",
        "\n",
        "# We will train on the full dataset without any random split\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_scaled, y_clean)\n",
        "y_pred = svm.predict(X_scaled)\n",
        "accuracy = accuracy_score(y_clean, y_pred)\n",
        "report = classification_report(y_clean, y_pred)\n",
        "print(f\"Accuracy of SVM classifier with linear kernel: {accuracy * 100:.2f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Identifying where the linear kernel fails:\n",
        "incorrectly_classified = np.where(y_clean != y_pred)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjqoRvnayP6l"
      },
      "outputs": [],
      "source": [
        "numDataPoints = X_scaled_T.shape[1]\n",
        "numMislabelled = len(incorrectly_classified)\n",
        "correct_labels = y_clean  # we have no correct labels\n",
        "data = X_scaled_T\n",
        "labels = y_pred  # corrupted labels\n",
        "t = numDataPoints\n",
        "N = 5000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goIqlW83yP6l"
      },
      "source": [
        "# Accuracy Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EC_t8Ln3yP6l"
      },
      "outputs": [],
      "source": [
        "quantile_list = [0.85, 0.9, 0.92, 0.96]\n",
        "residual_list = []\n",
        "\n",
        "for q in quantile_list:\n",
        "  intermediateResiduals = []\n",
        "  for i in range(nTrials):\n",
        "      x, residuals, _ = perceptronModified(data, labels, q, numDataPoints, N, correct_labels, numMislabelled, numDataPoints)\n",
        "      intermediateResiduals.append(residuals)\n",
        "\n",
        "  intermediateResiduals = np.mean(intermediateResiduals, axis = 0)\n",
        "  residual_list.append(intermediateResiduals)  # Store residuals for each quantile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7x9MyMpyP6l"
      },
      "outputs": [],
      "source": [
        "line_styles = ['-', '--', ':', '-.']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for idx, residuals in enumerate(residual_list):\n",
        "    x = np.arange(len(residuals))\n",
        "    plt.plot(x, residuals, label=f'{quantile_list[idx]}', linestyle=line_styles[idx], linewidth=3)\n",
        "\n",
        "plt.xlim(0, N)\n",
        "plt.ylim(20, 80)\n",
        "plt.yticks(np.arange(0, 110, 10), fontsize=14)\n",
        "plt.xticks(fontsize=14)\n",
        "plt.xlabel('Iterations', fontsize=16)\n",
        "plt.ylabel('Percent of Misclassified Inequalities', fontsize=16)\n",
        "plt.legend(title='Quantile', fontsize=14, title_fontsize=16)\n",
        "plt.grid(True)\n",
        "plt.savefig('Occupancy_final_plot.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyT-NIHlyP6x"
      },
      "source": [
        "# Timing the iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUTm_HaWyP6x"
      },
      "outputs": [],
      "source": [
        "sampled_indices_list = [5000, 15000, 20560]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFQizBkGyP6x"
      },
      "outputs": [],
      "source": [
        "residual_list = []\n",
        "residual_errors = []\n",
        "residual_dict = {}\n",
        "error_dict = {}\n",
        "for t in sampled_indices_list:\n",
        "    residual_list_i = []\n",
        "    residual_errors_i = []\n",
        "    for i in range(nTrials):\n",
        "        x, residuals, residuals_time = perceptronModified(data, labels, 0.96, t, N, correct_labels, numMislabelled, numDataPoints)\n",
        "        # Append the results for this iteration\n",
        "        residual_list_i.append(residuals_time)  # residuals_time = time\n",
        "        residual_errors_i.append(residuals)  # residuals = error\n",
        "\n",
        "    avg_residual_time = np.mean(residual_list_i, axis=0)\n",
        "    avg_residual_error = np.mean(residual_errors_i, axis=0)\n",
        "    residual_list.append(avg_residual_time)\n",
        "    residual_errors.append(avg_residual_error)\n",
        "    residual_dict[t] = avg_residual_time\n",
        "    error_dict[t] = avg_residual_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xMiSbBKyP6x"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "for idx, t in enumerate(sampled_indices_list):\n",
        "    x_values = residual_dict[t]\n",
        "    y_values = error_dict[t]\n",
        "    line_style = line_styles[idx % len(line_styles)]\n",
        "    marker = markers[idx % len(markers)]\n",
        "    plt.plot(x_values, y_values, label=f'{t}', linestyle=line_style, marker=marker, linewidth=3)\n",
        "\n",
        "plt.xlabel('Time (in seconds)', fontsize=16)\n",
        "plt.ylabel('Percent of Misclassified Inequalities', fontsize=16)\n",
        "plt.legend(title='Number Sampled Indices', fontsize=14, title_fontsize=16, loc='upper right')\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.grid(True, which='both', axis='both')\n",
        "plt.xlim(left=0)\n",
        "plt.ylim(bottom=0)\n",
        "plt.savefig('time_sampled_indices_q_equals_0.96_5000_Occupancy_iterations.png', dpi=300, bbox_inches='tight')  # Save with high resolution\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
