{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "givJsqPV-o4Y"
   },
   "source": [
    "# Necessary installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3d_TGWg8yP6f",
    "outputId": "5d0e928f-ff2e-42f8-d6b2-772384dcec4a"
   },
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install ucimlrepo\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6q1nOvwyP6g"
   },
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wU-nVOklyP6g"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import random\n",
    "import time  # Importing time module for tracking elapsed time\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wj7XLTjC4Mrw"
   },
   "source": [
    "# Importing the functions files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMwuoX2oyP6h"
   },
   "outputs": [],
   "source": [
    "def QuantileRK(A, b, q, t, N, correct_labels, labels, numMislabelled, numDataPoints):\n",
    "    A = np.array(A)\n",
    "    m, n = A.shape\n",
    "    x = np.random.rand(n)  # Initial guess for the solution\n",
    "    residuals = []  # To store the residuals for plotting\n",
    "    cumulative_times = []  # List to store cumulative times\n",
    "\n",
    "    # Create a boolean mask for the labels that are in correct_labels but not in labels\n",
    "    difference_mask = np.where(correct_labels == labels)  # Only retain the spots where they are equal\n",
    "\n",
    "    # Apply the mask to filter the rows\n",
    "    A_uncorrupted = A[difference_mask]\n",
    "    b_uncorrupted = b[difference_mask]\n",
    "\n",
    "    random.seed(0)  # For reproducibility\n",
    "\n",
    "    cumulative_time = 0  # Initialize cumulative time\n",
    "\n",
    "    # Iterate for N steps\n",
    "    for j in range(N):\n",
    "        start_time = time.time()  # Start time for this iteration\n",
    "\n",
    "        condition = np.dot(A_uncorrupted, x) > b_uncorrupted  # Compute the condition\n",
    "\n",
    "        # Count the number of elements that satisfy the condition as a percent of correct inequalities\n",
    "        not_set_count = np.count_nonzero(condition) / (numDataPoints - numMislabelled) * 100\n",
    "\n",
    "        residuals.append(not_set_count)\n",
    "\n",
    "        # ALGORITHM IS FROM HERE DOWN\n",
    "        # Randomly sample t indices from the set of m indices\n",
    "        sampled_indices = np.random.choice(m, t, replace=True)\n",
    "\n",
    "        # Pick a random index k from the m rows\n",
    "        k = random.choice(np.arange(m))\n",
    "        a_k = A[k]\n",
    "        b_k = b[k]\n",
    "\n",
    "        # Compute the expression for the selected index\n",
    "        e = np.maximum((np.dot(x, a_k) - b_k), 0)\n",
    "\n",
    "        # Residuals for the sampled indices\n",
    "        nyet_list_of_distances = A[sampled_indices] @ x - b[sampled_indices]\n",
    "        nonnegative_residuals = np.maximum(nyet_list_of_distances, 0)  # Non-negative residuals\n",
    "\n",
    "        if e <= np.quantile(nonnegative_residuals, q):\n",
    "            x = x - e * a_k\n",
    "        else:\n",
    "            x = x  # No update if the condition is not satisfied\n",
    "\n",
    "        end_time = time.time() # End time for this iteration\n",
    "        iteration_time = end_time - start_time\n",
    "        cumulative_time += iteration_time\n",
    "        cumulative_times.append(cumulative_time)  # Store the cumulative time\n",
    "\n",
    "    return x, residuals, cumulative_times\n",
    "\n",
    "def perceptronModified(data, labels, q, t, N, correct_labels, numMislabelled, numDataPoints):\n",
    "    n, m = data.shape\n",
    "    X = data.T\n",
    "    Y = labels\n",
    "    Y = np.diag(Y)\n",
    "    X_tilda = np.matmul(Y, X)\n",
    "    X_tilda = np.negative(X_tilda)\n",
    "    x, residuals, cumulative_times = QuantileRK(X_tilda, np.zeros((m,)), q, t, N, correct_labels, labels, numMislabelled, numDataPoints)\n",
    "\n",
    "    return x, residuals, cumulative_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxjuYaZKf_ek"
   },
   "source": [
    "# Sampled Indices: Timing them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rbC55HoZLyMH"
   },
   "source": [
    "# Real World Data Set: Banknote Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIhx1m7gNnMQ"
   },
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Fetch the Banknote Authentication Dataset\n",
    "banknote_data = fetch_ucirepo(id=267)\n",
    "\n",
    "# Extract features and target\n",
    "X = banknote_data.data.features # Features (variance, skewness, etc.)\n",
    "y = banknote_data.data.targets\n",
    "\n",
    "X = X.values\n",
    "y = y.values\n",
    "y = y.ravel()\n",
    "y = 2*y-1 # to make it fit our algorithm\n",
    "\n",
    "# Scale the features (standardize them)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_T = X_scaled.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8h3DukxAyP6i"
   },
   "source": [
    "# We set the SVM baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCLemHrAyP6i",
    "outputId": "04c71213-c8d0-499f-df82-79feb2307a3b"
   },
   "outputs": [],
   "source": [
    "# We will train on the full dataset without any random split\n",
    "svm = SVC(kernel='linear')  # Linear kernel for decision boundary\n",
    "svm.fit(X_scaled, y)  # Train on the full dataset to get linear truth labels\n",
    "\n",
    "# Predict the labels using the trained model\n",
    "y_pred = svm.predict(X_scaled)\n",
    "\n",
    "# Evaluate the predictions by comparing with the true labels\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "report = classification_report(y, y_pred)\n",
    "\n",
    "print(f\"Accuracy of SVM classifier with linear kernel: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "incorrectly_classified = np.where(y != y_pred)[0]\n",
    "misclassified = 1 - accuracy # just to store the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rS3bmwFEyP6j",
    "outputId": "64351edf-ce96-429a-9c9a-ec295e940c09"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Code to check how balanced is the dataset.\n",
    "'''\n",
    "\n",
    "count_ones = np.sum(y == 1)\n",
    "count_minus_ones = np.sum(y == -1)\n",
    "\n",
    "print(f\"Number of 1s in y: {count_ones}\")\n",
    "print(f\"Number of -1s in y: {count_minus_ones}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bdfl0bxAa9Qy"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Setting the parameters for the algorithm\n",
    "'''\n",
    "\n",
    "numDataPoints = X_scaled_T.shape[1]\n",
    "numMislabelled = len(incorrectly_classified)\n",
    "correct_labels = y_pred\n",
    "data = X_scaled_T\n",
    "labels = y\n",
    "t = numDataPoints\n",
    "N = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vPLO-xJViG_"
   },
   "outputs": [],
   "source": [
    "quantile_list = [0.85, 0.9, 0.95, 0.97]\n",
    "residual_list = []  # Dictionary to store residuals for each quantile\n",
    "nTrials = 10 # how many rounds of averaging we wish to do\n",
    "\n",
    "for q in quantile_list:\n",
    "  intermediateResiduals = []\n",
    "  for i in range(nTrials):\n",
    "      x, residuals, _ = perceptronModified(data, labels, q, numDataPoints, N, correct_labels, numMislabelled, numDataPoints)\n",
    "      intermediateResiduals.append(residuals)\n",
    "\n",
    "  intermediateResiduals = np.mean(intermediateResiduals, axis = 0)\n",
    "  residual_list.append(intermediateResiduals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "id": "6jTdZ3Q1yP6k",
    "outputId": "6c34a14a-b48e-4edb-f772-f6c28beb067f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "line_styles = ['-', '--', ':', '-.']\n",
    "\n",
    "# Create a plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for idx, residuals in enumerate(residual_list):\n",
    "    # Ensure x matches the length of residuals (assuming iteration count is equal to len(residuals))\n",
    "    x = np.arange(len(residuals))\n",
    "\n",
    "    plt.plot(x, residuals, label=f'{quantile_list[idx]}', linestyle=line_styles[idx], linewidth=3)\n",
    "\n",
    "\n",
    "plt.xlim(0, N)\n",
    "plt.ylim(20, 80)\n",
    "plt.yticks(np.arange(0, 110, 10), fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xlabel('Iterations', fontsize=16)\n",
    "plt.ylabel('Percent of Misclassified Inequalities', fontsize=16)\n",
    "plt.legend(title='Quantile', fontsize=14, title_fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.savefig('banknotes_data_final_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1h46QlrYyP6k"
   },
   "outputs": [],
   "source": [
    "sampled_indices_list = [450, 900, 1372]\n",
    "line_styles = ['-', '--', ':']\n",
    "markers = ['o', 's', '*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMrwBHKnyP6k"
   },
   "outputs": [],
   "source": [
    "residual_list = []\n",
    "residual_errors = []\n",
    "residual_dict = {}\n",
    "error_dict = {}\n",
    "\n",
    "for t in sampled_indices_list:\n",
    "    residual_list_i = []\n",
    "    residual_errors_i = []\n",
    "    for i in range(nTrials):\n",
    "        x, residuals, residuals_time = perceptronModified(data, labels, 0.97, t, N, correct_labels, numMislabelled, numDataPoints)\n",
    "        residual_list_i.append(residuals_time)\n",
    "        residual_errors_i.append(residuals)\n",
    "        \n",
    "    avg_residual_time = np.mean(residual_list_i, axis=0)\n",
    "    avg_residual_error = np.mean(residual_errors_i, axis=0)\n",
    "    residual_list.append(avg_residual_time)\n",
    "    residual_errors.append(avg_residual_error)\n",
    "    residual_dict[t] = avg_residual_time\n",
    "    error_dict[t] = avg_residual_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "822IWVFuyP6k",
    "outputId": "0ba6cec7-a628-4177-d6c4-96f0c4eb10bc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for idx, t in enumerate(sampled_indices_list):\n",
    "    x_values = residual_dict[t]\n",
    "    y_values = error_dict[t]\n",
    "\n",
    "    line_style = line_styles[idx % len(line_styles)]\n",
    "    marker = markers[idx % len(markers)]\n",
    "\n",
    "    plt.plot(x_values, y_values, label=f'{t}', linestyle=line_style, marker=marker, linewidth=3)\n",
    "\n",
    "plt.xlabel('Time (in seconds)', fontsize=16)\n",
    "plt.ylabel('Percent of Misclassified Inequalities', fontsize=16)\n",
    "plt.legend(title='Number Sampled Indices', fontsize=14, title_fontsize=16, loc='upper right')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.grid(True, which='both', axis='both')\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "# Save the figure as a PNG file\n",
    "plt.savefig('time_sampled_indices_q_equals_0.97_5000_banknotes_final_iterations.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b6hJb8yrMe4"
   },
   "source": [
    "# Occupancy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTtvMw36lple"
   },
   "outputs": [],
   "source": [
    "occupancy_detection = fetch_ucirepo(id=357)\n",
    "occupancy_detection.data.features = occupancy_detection.data.features.drop(columns=['date']) # Drop the 'date' column\n",
    "# Convert numeric columns to the correct data type using .loc\n",
    "occupancy_detection.data.features.loc[:, 'Temperature'] = pd.to_numeric(occupancy_detection.data.features['Temperature'], errors='coerce')\n",
    "occupancy_detection.data.features.loc[:, 'Humidity'] = pd.to_numeric(occupancy_detection.data.features['Humidity'], errors='coerce')\n",
    "occupancy_detection.data.features.loc[:, 'Light'] = pd.to_numeric(occupancy_detection.data.features['Light'], errors='coerce')\n",
    "occupancy_detection.data.features.loc[:, 'CO2'] = pd.to_numeric(occupancy_detection.data.features['CO2'], errors='coerce')\n",
    "occupancy_detection.data.features.loc[:, 'HumidityRatio'] = pd.to_numeric(occupancy_detection.data.features['HumidityRatio'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "471D98LNy49q"
   },
   "outputs": [],
   "source": [
    "X = occupancy_detection.data.features\n",
    "y = occupancy_detection.data.targets\n",
    "# Drop NaN rows\n",
    "X_clean = X.drop(index=[8143, 10809])\n",
    "y_clean = y.drop(index=[8143, 10809])\n",
    "\n",
    "# Convert y_clean to NumPy and transform it into {-1, 1}\n",
    "y_clean = y_clean.values.ravel()\n",
    "y_clean = 2 * y_clean - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFe9FKUGyP6k"
   },
   "source": [
    "# We set the SVM baseline again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3aZ19az-yP6k"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_clean)\n",
    "X_scaled_T = X_scaled.T\n",
    "\n",
    "# We will train on the full dataset without any random split\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_scaled, y_clean)\n",
    "y_pred = svm.predict(X_scaled)\n",
    "accuracy = accuracy_score(y_clean, y_pred)\n",
    "report = classification_report(y_clean, y_pred)\n",
    "print(f\"Accuracy of SVM classifier with linear kernel: {accuracy * 100:.2f}%\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Identifying where the linear kernel fails:\n",
    "incorrectly_classified = np.where(y_clean != y_pred)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjqoRvnayP6l"
   },
   "outputs": [],
   "source": [
    "numDataPoints = X_scaled_T.shape[1]\n",
    "numMislabelled = len(incorrectly_classified)\n",
    "correct_labels = y_clean  # we have no correct labels\n",
    "data = X_scaled_T\n",
    "labels = y_pred  # corrupted labels\n",
    "t = numDataPoints\n",
    "N = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goIqlW83yP6l"
   },
   "source": [
    "# Accuracy Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EC_t8Ln3yP6l"
   },
   "outputs": [],
   "source": [
    "quantile_list = [0.85, 0.9, 0.92, 0.96]\n",
    "residual_list = []\n",
    "\n",
    "for q in quantile_list:\n",
    "  intermediateResiduals = []\n",
    "  for i in range(nTrials):\n",
    "      x, residuals, _ = perceptronModified(data, labels, q, numDataPoints, N, correct_labels, numMislabelled, numDataPoints)\n",
    "      intermediateResiduals.append(residuals)\n",
    "\n",
    "  intermediateResiduals = np.mean(intermediateResiduals, axis = 0)\n",
    "  residual_list.append(intermediateResiduals)  # Store residuals for each quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7x9MyMpyP6l"
   },
   "outputs": [],
   "source": [
    "line_styles = ['-', '--', ':', '-.']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for idx, residuals in enumerate(residual_list):\n",
    "    x = np.arange(len(residuals))\n",
    "    plt.plot(x, residuals, label=f'{quantile_list[idx]}', linestyle=line_styles[idx], linewidth=3)\n",
    "\n",
    "plt.xlim(0, N)\n",
    "plt.ylim(20, 80)\n",
    "plt.yticks(np.arange(0, 110, 10), fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xlabel('Iterations', fontsize=16)\n",
    "plt.ylabel('Percent of Misclassified Inequalities', fontsize=16)\n",
    "plt.legend(title='Quantile', fontsize=14, title_fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.savefig('Occupancy_final_plot.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyT-NIHlyP6x"
   },
   "source": [
    "# Timing the iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUTm_HaWyP6x"
   },
   "outputs": [],
   "source": [
    "sampled_indices_list = [5000, 15000, 20560]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zFQizBkGyP6x"
   },
   "outputs": [],
   "source": [
    "residual_list = []\n",
    "residual_errors = []\n",
    "residual_dict = {}\n",
    "error_dict = {}\n",
    "for t in sampled_indices_list:\n",
    "    residual_list_i = []\n",
    "    residual_errors_i = []\n",
    "    for i in range(nTrials):\n",
    "        x, residuals, residuals_time = perceptronModified(data, labels, 0.96, t, N, correct_labels, numMislabelled, numDataPoints)\n",
    "        # Append the results for this iteration\n",
    "        residual_list_i.append(residuals_time)  # residuals_time = time\n",
    "        residual_errors_i.append(residuals)  # residuals = error\n",
    "\n",
    "    avg_residual_time = np.mean(residual_list_i, axis=0)\n",
    "    avg_residual_error = np.mean(residual_errors_i, axis=0)\n",
    "    residual_list.append(avg_residual_time)\n",
    "    residual_errors.append(avg_residual_error)\n",
    "    residual_dict[t] = avg_residual_time\n",
    "    error_dict[t] = avg_residual_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9xMiSbBKyP6x"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for idx, t in enumerate(sampled_indices_list):\n",
    "    x_values = residual_dict[t]\n",
    "    y_values = error_dict[t]\n",
    "    line_style = line_styles[idx % len(line_styles)]\n",
    "    marker = markers[idx % len(markers)]\n",
    "    plt.plot(x_values, y_values, label=f'{t}', linestyle=line_style, marker=marker, linewidth=3)\n",
    "\n",
    "plt.xlabel('Time (in seconds)', fontsize=16)\n",
    "plt.ylabel('Percent of Misclassified Inequalities', fontsize=16)\n",
    "plt.legend(title='Number Sampled Indices', fontsize=14, title_fontsize=16, loc='upper right')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.grid(True, which='both', axis='both')\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(bottom=0)\n",
    "plt.savefig('time_sampled_indices_q_equals_0.96_5000_Occupancy_iterations.png', dpi=300, bbox_inches='tight')  # Save with high resolution\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
