{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRshFPwH-lNx"
      },
      "source": [
        "# Import Statements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsYOiwuHkfXc"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34ATJHI6x9RH"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "These are our import statements\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "import random\n",
        "import time  # Importing time module for tracking elapsed time\n",
        "from sklearn.svm import LinearSVC  # Import the SVM classifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13s_aMdtkfXd"
      },
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/jamiehadd/QuantileRKIandPerceptron/refs/heads/main/functions_QRK.py'\n",
        "!wget --no-cache --backups=1 {url}\n",
        "from functions_QRK import perceptronModified"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# $\\beta = 0.01$ Experiments\n",
        "\n"
      ],
      "metadata": {
        "id": "RxqJqrLxU5Fw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfWeUy2h-w08"
      },
      "source": [
        "# Synthesize the normally distributed data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnq3sWb394er"
      },
      "outputs": [],
      "source": [
        "numDataPoints = 50000\n",
        "numFeatures = 100\n",
        "data = np.random.normal(0, 1, size=(numFeatures, numDataPoints))  # Mean=0, S.D. = 1, generates a 100x50000 array\n",
        "# Normalize the data\n",
        "for i in range(data.shape[1]):\n",
        "    data[:, i] = data[:, i] / np.linalg.norm(data[:, i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nj4GHbfRgtNZ"
      },
      "outputs": [],
      "source": [
        "# True decision boundary separating the 2 classes of data\n",
        "w_true = np.random.normal(0, 1, size=(numFeatures, 1))\n",
        "\n",
        "# Identify points on either side of the line {x: w_true^T x = 0}\n",
        "labels = np.zeros((1, data.shape[1]))\n",
        "for col_ind in range(data.shape[1]):\n",
        "    if np.dot(data[:, col_ind], w_true) < 0:\n",
        "        labels[0, col_ind] = -1\n",
        "    else:\n",
        "        labels[0, col_ind] = 1\n",
        "\n",
        "correct_labels = labels.copy()\n",
        "# Create a dictionary with the data points and their labels\n",
        "original_data_dict = {}\n",
        "for i in range(data.shape[1]):\n",
        "    key = tuple(data[:, i])\n",
        "    value = labels[0, i]\n",
        "    original_data_dict[key] = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSWs29jn-CkG"
      },
      "outputs": [],
      "source": [
        "'''Mislabel points'''\n",
        "\n",
        "# Number of mislabelled points\n",
        "numMislabelled = 500\n",
        "\n",
        "fraction_corrupted = numMislabelled / data.shape[1]\n",
        "print(f\"Fraction corrupted: {fraction_corrupted}\")\n",
        "\n",
        "indices = np.where(labels[0] == 1)[0]\n",
        "\n",
        "# Mislabel the first `numMislabelled` points from the positive class\n",
        "mislabelled_indices = indices[:numMislabelled]\n",
        "labels[0, mislabelled_indices] = -1\n",
        "\n",
        "# Now, create a dictionary that includes all data points with their possibly mislabelled labels\n",
        "mislabelled_data_dict = {}\n",
        "\n",
        "# Store the mislabelled data points in the dictionary\n",
        "for i in range(data.shape[1]):\n",
        "    key = tuple(data[:, i])  # Use tuple of the data point as the key\n",
        "    value = labels[0, i]  # Corresponding label (either 1 or -1)\n",
        "    mislabelled_data_dict[key] = value\n",
        "\n",
        "mislabelled_points = {key: value for key, value in mislabelled_data_dict.items() if value == -1}\n",
        "new_labels = np.array(list(original_data_dict.values()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBiuxfJFkfXg"
      },
      "outputs": [],
      "source": [
        "correct_labels = correct_labels.reshape(-1) # essential line to reshape array\n",
        "labels = labels.reshape(-1) # essential line to reshape array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUacsJLPkfXg"
      },
      "outputs": [],
      "source": [
        "y_test = correct_labels\n",
        "X_train, y_train = data.T, labels\n",
        "svm_model = LinearSVC(dual=False)\n",
        "svm_model.fit(X_train, y_train)\n",
        "w = svm_model.coef_[0]\n",
        "b = svm_model.intercept_[0]\n",
        "# Manually calculate predictions for X_test using the decision function\n",
        "y_pred = np.sign(np.dot(X_train, w) + b)  # Decision function: w * X + b\n",
        "difference_mask = np.where(correct_labels == labels)  # Only retain the spots where they are equal\n",
        "y_predUncorrupted = y_pred[difference_mask]\n",
        "y_testUncorrupted = y_test[difference_mask]\n",
        "# Now compare these predictions to the true labels (y_test)\n",
        "accuracy = accuracy_score(y_predUncorrupted, y_testUncorrupted)\n",
        "# Print results\n",
        "print(\"Manual predictions:\", y_predUncorrupted)\n",
        "print(\"True labels (y_test):\", y_testUncorrupted)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7tbsazM-zy9"
      },
      "source": [
        "# Function call and error plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i29wpqsPK18y"
      },
      "outputs": [],
      "source": [
        "quantile_list = [0.9, 0.95, 0.99, 1]\n",
        "residual_list = []\n",
        "\n",
        "numTrials = 5\n",
        "numIterations = 25000\n",
        "for q in quantile_list:\n",
        "  intermediateResiduals = []\n",
        "  for i in range(numTrials):\n",
        "      x, residuals, _ = perceptronModified(data, labels, q, numDataPoints, numIterations, correct_labels, numMislabelled, numDataPoints)\n",
        "      intermediateResiduals.append(residuals)\n",
        "  intermediateResiduals = np.mean(intermediateResiduals, axis = 0)\n",
        "  residual_list.append(intermediateResiduals)  # Store residuals for each quantile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVKYUjAAshpV"
      },
      "outputs": [],
      "source": [
        "line_styles = ['-', '--', '-.', ':']\n",
        "plt.figure(figsize=(8, 6))\n",
        "for idx, residuals in enumerate(residual_list):\n",
        "    x = np.arange(len(residuals))\n",
        "    plt.plot(x, residuals, label=f'{quantile_list[idx]}', linestyle=line_styles[idx], linewidth=3)\n",
        "\n",
        "plt.xlim(0, numIterations)\n",
        "plt.yticks(np.arange(0, 110, 10), fontsize=14)\n",
        "plt.xticks(fontsize=14)\n",
        "plt.xlabel('Iterations', fontsize=16)\n",
        "plt.ylabel('Percent of Misclassified Inequalities', fontsize=16)\n",
        "plt.legend(title='Quantile', fontsize=14, title_fontsize=16)  # Increase legend title font size\n",
        "plt.grid(True)\n",
        "plt.savefig('beta_equals_0.01.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxjuYaZKf_ek"
      },
      "source": [
        "# Sampled Indices: Timing them\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MECLyx_Mf_RZ"
      },
      "outputs": [],
      "source": [
        "sampled_indices_list = [1000, 25000, 50000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PnvNjAriRMG"
      },
      "outputs": [],
      "source": [
        "residual_list = []  # Residual times for each sampled index\n",
        "residual_errors = []  # Residual errors for each sampled index\n",
        "residual_dict = {}  # Dictionary to store residual_list for each t value\n",
        "error_dict = {}  # Dictionary to store residual_errors for each t value\n",
        "q = 1-fraction_corrupted\n",
        "trials = 5\n",
        "numIters = 25000\n",
        "\n",
        "for t in sampled_indices_list:\n",
        "    residual_list_i = []\n",
        "    residual_errors_i = []\n",
        "    for i in range(trials):\n",
        "        x, residuals, residuals_time = perceptronModified(data, labels, q, t, numIters, correct_labels, numMislabelled, numDataPoints)\n",
        "        residual_list_i.append(residuals_time)\n",
        "        residual_errors_i.append(residuals)\n",
        "    # Average the results for this sampled index across the iterations\n",
        "    avg_residual_time = np.mean(residual_list_i, axis=0)\n",
        "    avg_residual_error = np.mean(residual_errors_i, axis=0)\n",
        "\n",
        "    # Append to the overall list\n",
        "    residual_list.append(avg_residual_time)\n",
        "    residual_errors.append(avg_residual_error)\n",
        "\n",
        "    # Store the average residual times and errors for this t value in the corresponding dictionaries\n",
        "    residual_dict[t] = avg_residual_time\n",
        "    error_dict[t] = avg_residual_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3F0Q6AURxZ91"
      },
      "outputs": [],
      "source": [
        "line_styles = ['-', '--', '-.', ':']\n",
        "markers = ['o', 's', '^', 'D']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "for idx, t in enumerate(sampled_indices_list):\n",
        "    x_values = residual_dict[t]\n",
        "    y_values = error_dict[t]\n",
        "    line_style = line_styles[idx % len(line_styles)]\n",
        "    marker = markers[idx % len(markers)]\n",
        "    plt.plot(x_values, y_values, label=f'{t}', linestyle=line_style, marker=marker, linewidth=3)\n",
        "\n",
        "plt.xlabel('Time (in seconds)', fontsize=16)\n",
        "plt.ylabel('Percent of Misclassified Inequalities', fontsize=16)\n",
        "plt.legend(title='Number Sampled Indices', fontsize=14, title_fontsize=16, loc='upper right')\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.grid(True, which='both', axis='both')\n",
        "plt.xlim(left=0)\n",
        "plt.ylim(bottom=0)\n",
        "plt.savefig('time_sampled_indices_q_equals_0.99.png', dpi=300, bbox_inches='tight')  # Save with high resolution\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# $\\beta = 0.05$ Experiments\n"
      ],
      "metadata": {
        "id": "LyDAGmiWTn8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Synthesize the normally distributed data set"
      ],
      "metadata": {
        "id": "VviJdrpcTsNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Synthesize 2D data points and normalize them\n",
        "numDataPoints = 50000\n",
        "numFeatures = 100\n",
        "data = np.random.normal(0, 1, size=(numFeatures, numDataPoints))  # Mean=0, S.D. = 1, generates a 100x50000 array\n",
        "# Normalize the data\n",
        "for i in range(data.shape[1]):\n",
        "    data[:, i] = data[:, i] / np.linalg.norm(data[:, i])"
      ],
      "metadata": {
        "id": "34Ah4TamTtFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# True decision boundary separating the 2 classes of data\n",
        "w_true = np.random.normal(0, 1, size=(numFeatures, 1))\n",
        "\n",
        "# Identify points on either side of the line {x: w_true^T x = 0}\n",
        "labels = np.zeros((1, data.shape[1]))\n",
        "for col_ind in range(data.shape[1]):\n",
        "    if np.dot(data[:, col_ind], w_true) < 0:\n",
        "        labels[0, col_ind] = -1\n",
        "    else:\n",
        "        labels[0, col_ind] = 1\n",
        "\n",
        "correct_labels = labels.copy()\n",
        "# Create a dictionary with the data points and their labels\n",
        "original_data_dict = {}\n",
        "for i in range(data.shape[1]):\n",
        "    key = tuple(data[:, i])\n",
        "    value = labels[0, i]\n",
        "    original_data_dict[key] = value"
      ],
      "metadata": {
        "id": "LhSbeTJrTvzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Mislabel points'''\n",
        "\n",
        "# Number of mislabelled points\n",
        "numMislabelled = 2500\n",
        "\n",
        "fraction_corrupted = numMislabelled / data.shape[1]\n",
        "print(f\"Fraction corrupted: {fraction_corrupted}\")\n",
        "\n",
        "indices = np.where(labels[0] == 1)[0]  # Find indices where labels are 1\n",
        "# Mislabel the first `numMislabelled` points from the positive class\n",
        "mislabelled_indices = indices[:numMislabelled]\n",
        "labels[0, mislabelled_indices] = -1\n",
        "\n",
        "# Now, create a dictionary that includes all data points with their possibly mislabelled labels\n",
        "mislabelled_data_dict = {}\n",
        "\n",
        "# Store the mislabelled data points in the dictionary\n",
        "for i in range(data.shape[1]):\n",
        "    key = tuple(data[:, i])  # Use tuple of the data point as the key\n",
        "    value = labels[0, i]  # Corresponding label (either 1 or -1)\n",
        "    mislabelled_data_dict[key] = value\n",
        "\n",
        "mislabelled_points = {key: value for key, value in mislabelled_data_dict.items() if value == -1}\n",
        "new_labels = np.array(list(original_data_dict.values()))"
      ],
      "metadata": {
        "id": "tGVtO-MpPgyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_labels = correct_labels.reshape(-1) # essential line to reshape array\n",
        "labels = labels.reshape(-1) # essential line to reshape array"
      ],
      "metadata": {
        "id": "-31wEHBga7JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = correct_labels\n",
        "X_train, y_train = data.T, labels\n",
        "svm_model = LinearSVC(dual=False)\n",
        "svm_model.fit(X_train, y_train)\n",
        "w = svm_model.coef_[0]\n",
        "b = svm_model.intercept_[0]\n",
        "# Manually calculate predictions for X_test using the decision function\n",
        "y_pred = np.sign(np.dot(X_train, w) + b)  # Decision function: w * X + b\n",
        "difference_mask = np.where(correct_labels == labels)  # Only retain the spots where they are equal\n",
        "y_predUncorrupted = y_pred[difference_mask]\n",
        "y_testUncorrupted = y_test[difference_mask]\n",
        "# Now compare these predictions to the true labels (y_test)\n",
        "accuracy = accuracy_score(y_predUncorrupted, y_testUncorrupted)\n",
        "# Print results\n",
        "print(\"Manual predictions:\", y_predUncorrupted)\n",
        "print(\"True labels (y_test):\", y_testUncorrupted)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "nwdEFsU5QHDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Call and error plot"
      ],
      "metadata": {
        "id": "u0XBEKW5QZCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantile_list = [0.85, 0.9, 0.95, 1]\n",
        "residual_list = []\n",
        "\n",
        "numTrials = 5\n",
        "numIterations = 25000\n",
        "for q in quantile_list:\n",
        "  intermediateResiduals = []\n",
        "  for i in range(numTrials):\n",
        "      x, residuals, _ = perceptronModified(data, labels, q, numDataPoints, numIterations, correct_labels, numMislabelled, numDataPoints)\n",
        "      intermediateResiduals.append(residuals)\n",
        "  intermediateResiduals = np.mean(intermediateResiduals, axis = 0)\n",
        "  residual_list.append(intermediateResiduals)  # Store residuals for each quantile"
      ],
      "metadata": {
        "id": "INoMZrPkQJ7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line_styles = ['-', '--', '-.', ':']\n",
        "plt.figure(figsize=(8, 6))\n",
        "for idx, residuals in enumerate(residual_list):\n",
        "    x = np.arange(len(residuals))\n",
        "    plt.plot(x, residuals, label=f'{quantile_list[idx]}', linestyle=line_styles[idx], linewidth=3)\n",
        "\n",
        "plt.xlim(0, numIterations)\n",
        "plt.yticks(np.arange(0, 110, 10), fontsize=14)\n",
        "plt.xticks(fontsize=14)\n",
        "plt.xlabel('Iterations', fontsize=16)\n",
        "plt.ylabel('Percent of Misclassified Inequalities', fontsize=16)\n",
        "plt.legend(title='Quantile', fontsize=14, title_fontsize=16)  # Increase legend title font size\n",
        "plt.grid(True)\n",
        "plt.savefig('beta_equals_0.05.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N5GjJL1AQiaF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampled Indices: Timing them\n"
      ],
      "metadata": {
        "id": "1fT4FRlVRNDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices_list = [1000, 25000, 50000]"
      ],
      "metadata": {
        "id": "t21emss3QrLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residual_list = []  # Residual times for each sampled index\n",
        "residual_errors = []  # Residual errors for each sampled index\n",
        "residual_dict = {}  # Dictionary to store residual_list for each t value\n",
        "error_dict = {}  # Dictionary to store residual_errors for each t value\n",
        "q = 1-fraction_corrupted\n",
        "trials = 5\n",
        "numIters = 25000\n",
        "\n",
        "for t in sampled_indices_list:\n",
        "    residual_list_i = []\n",
        "    residual_errors_i = []\n",
        "    for i in range(trials):\n",
        "        x, residuals, residuals_time = perceptronModified(data, labels, q, t, numIters, correct_labels, numMislabelled, numDataPoints)\n",
        "        residual_list_i.append(residuals_time)\n",
        "        residual_errors_i.append(residuals)\n",
        "    # Average the results for this sampled index across the iterations\n",
        "    avg_residual_time = np.mean(residual_list_i, axis=0)\n",
        "    avg_residual_error = np.mean(residual_errors_i, axis=0)\n",
        "\n",
        "    # Append to the overall list\n",
        "    residual_list.append(avg_residual_time)\n",
        "    residual_errors.append(avg_residual_error)\n",
        "\n",
        "    # Store the average residual times and errors for this t value in the corresponding dictionaries\n",
        "    residual_dict[t] = avg_residual_time\n",
        "    error_dict[t] = avg_residual_error"
      ],
      "metadata": {
        "id": "4I9iPRcjRXOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line_styles = ['-', '--', '-.', ':']\n",
        "markers = ['o', 's', '^', 'D']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "for idx, t in enumerate(sampled_indices_list):\n",
        "    x_values = residual_dict[t]\n",
        "    y_values = error_dict[t]\n",
        "    line_style = line_styles[idx % len(line_styles)]\n",
        "    marker = markers[idx % len(markers)]\n",
        "    plt.plot(x_values, y_values, label=f'{t}', linestyle=line_style, marker=marker, linewidth=3)\n",
        "\n",
        "plt.xlabel('Time (in seconds)', fontsize=16)\n",
        "plt.ylabel('Percent of Misclassified Inequalities', fontsize=16)\n",
        "plt.legend(title='Number Sampled Indices', fontsize=14, title_fontsize=16, loc='upper right')\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.grid(True, which='both', axis='both')\n",
        "plt.xlim(left=0)\n",
        "plt.ylim(bottom=0)\n",
        "plt.savefig('time_sampled_indices_q_equals_0.95.png', dpi=300, bbox_inches='tight')  # Save with high resolution\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kiUpU5vyRZhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# $\\beta = 0.10$ Experiments"
      ],
      "metadata": {
        "id": "-4COGHKKRiYP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Synthesize the normally distributed data set"
      ],
      "metadata": {
        "id": "I_ENrPxhUTD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Synthesize 2D data points and normalize them\n",
        "numDataPoints = 50000\n",
        "numFeatures = 100\n",
        "data = np.random.normal(0, 1, size=(numFeatures, numDataPoints))  # Mean=0, S.D. = 1, generates a 100x50000 array\n",
        "# Normalize the data\n",
        "for i in range(data.shape[1]):\n",
        "    data[:, i] = data[:, i] / np.linalg.norm(data[:, i])"
      ],
      "metadata": {
        "id": "CyS5oQ3CUIIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# True decision boundary separating the 2 classes of data\n",
        "w_true = np.random.normal(0, 1, size=(numFeatures, 1))\n",
        "\n",
        "# Identify points on either side of the line {x: w_true^T x = 0}\n",
        "labels = np.zeros((1, data.shape[1]))\n",
        "for col_ind in range(data.shape[1]):\n",
        "    if np.dot(data[:, col_ind], w_true) < 0:\n",
        "        labels[0, col_ind] = -1\n",
        "    else:\n",
        "        labels[0, col_ind] = 1\n",
        "\n",
        "correct_labels = labels.copy()\n",
        "# Create a dictionary with the data points and their labels\n",
        "original_data_dict = {}\n",
        "for i in range(data.shape[1]):\n",
        "    key = tuple(data[:, i])\n",
        "    value = labels[0, i]\n",
        "    original_data_dict[key] = value"
      ],
      "metadata": {
        "id": "DHRv7f7nUVZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Mislabel points'''\n",
        "\n",
        "# Number of mislabelled points\n",
        "numMislabelled = 5000\n",
        "\n",
        "fraction_corrupted = numMislabelled / data.shape[1]\n",
        "print(f\"Fraction corrupted: {fraction_corrupted}\")\n",
        "\n",
        "indices = np.where(labels[0] == 1)[0]  # Find indices where labels are 1\n",
        "# Mislabel the first `numMislabelled` points from the positive class\n",
        "mislabelled_indices = indices[:numMislabelled]\n",
        "labels[0, mislabelled_indices] = -1\n",
        "\n",
        "# Now, create a dictionary that includes all data points with their possibly mislabelled labels\n",
        "mislabelled_data_dict = {}\n",
        "\n",
        "# Store the mislabelled data points in the dictionary\n",
        "for i in range(data.shape[1]):\n",
        "    key = tuple(data[:, i])  # Use tuple of the data point as the key\n",
        "    value = labels[0, i]  # Corresponding label (either 1 or -1)\n",
        "    mislabelled_data_dict[key] = value\n",
        "\n",
        "mislabelled_points = {key: value for key, value in mislabelled_data_dict.items() if value == -1}\n",
        "new_labels = np.array(list(original_data_dict.values()))"
      ],
      "metadata": {
        "id": "xIPdJQhARq0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_labels = correct_labels.reshape(-1) # essential line to reshape array\n",
        "labels = labels.reshape(-1) # essential line to reshape array"
      ],
      "metadata": {
        "id": "1u8pHamNa9T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = correct_labels\n",
        "X_train, y_train = data.T, labels\n",
        "svm_model = LinearSVC(dual=False)\n",
        "svm_model.fit(X_train, y_train)\n",
        "w = svm_model.coef_[0]\n",
        "b = svm_model.intercept_[0]\n",
        "# Manually calculate predictions for X_test using the decision function\n",
        "y_pred = np.sign(np.dot(X_train, w) + b)  # Decision function: w * X + b\n",
        "difference_mask = np.where(correct_labels == labels)  # Only retain the spots where they are equal\n",
        "y_predUncorrupted = y_pred[difference_mask]\n",
        "y_testUncorrupted = y_test[difference_mask]\n",
        "# Now compare these predictions to the true labels (y_test)\n",
        "accuracy = accuracy_score(y_predUncorrupted, y_testUncorrupted)\n",
        "# Print results\n",
        "print(\"Manual predictions:\", y_predUncorrupted)\n",
        "print(\"True labels (y_test):\", y_testUncorrupted)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "HqnTDsHjR-5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function call and error plot"
      ],
      "metadata": {
        "id": "uUdoaepiSD4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantile_list = [0.85, 0.9, 0.95, 1]\n",
        "residual_list = []\n",
        "\n",
        "numTrials = 5\n",
        "numIterations = 25000\n",
        "for q in quantile_list:\n",
        "  intermediateResiduals = []\n",
        "  for i in range(numTrials):\n",
        "      x, residuals, _ = perceptronModified(data, labels, q, numDataPoints, numIterations, correct_labels, numMislabelled, numDataPoints)\n",
        "      intermediateResiduals.append(residuals)\n",
        "  intermediateResiduals = np.mean(intermediateResiduals, axis = 0)\n",
        "  residual_list.append(intermediateResiduals)  # Store residuals for each quantile"
      ],
      "metadata": {
        "id": "QxoKK48AR_YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line_styles = ['-', '--', '-.', ':']\n",
        "plt.figure(figsize=(8, 6))\n",
        "for idx, residuals in enumerate(residual_list):\n",
        "    x = np.arange(len(residuals))\n",
        "    plt.plot(x, residuals, label=f'{quantile_list[idx]}', linestyle=line_styles[idx], linewidth=3)\n",
        "\n",
        "plt.xlim(0, numIterations)\n",
        "plt.yticks(np.arange(0, 110, 10), fontsize=14)\n",
        "plt.xticks(fontsize=14)\n",
        "plt.xlabel('Iterations', fontsize=16)\n",
        "plt.ylabel('Percent of Misclassified Inequalities', fontsize=16)\n",
        "plt.legend(title='Quantile', fontsize=14, title_fontsize=16)  # Increase legend title font size\n",
        "plt.grid(True)\n",
        "plt.savefig('beta_equals_0.10.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mlOpNbsdSLra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampled Indices: Timing them\n"
      ],
      "metadata": {
        "id": "pv9Lgu09SRMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices_list = [1000, 25000, 50000]"
      ],
      "metadata": {
        "id": "feqeJzo-SOPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residual_list = []  # Residual times for each sampled index\n",
        "residual_errors = []  # Residual errors for each sampled index\n",
        "residual_dict = {}  # Dictionary to store residual_list for each t value\n",
        "error_dict = {}  # Dictionary to store residual_errors for each t value\n",
        "q = 1-fraction_corrupted\n",
        "trials = 5\n",
        "numIters = 25000\n",
        "\n",
        "for t in sampled_indices_list:\n",
        "    residual_list_i = []\n",
        "    residual_errors_i = []\n",
        "    for i in range(trials):\n",
        "        x, residuals, residuals_time = perceptronModified(data, labels, q, t, numIters, correct_labels, numMislabelled, numDataPoints)\n",
        "        residual_list_i.append(residuals_time)\n",
        "        residual_errors_i.append(residuals)\n",
        "    # Average the results for this sampled index across the iterations\n",
        "    avg_residual_time = np.mean(residual_list_i, axis=0)\n",
        "    avg_residual_error = np.mean(residual_errors_i, axis=0)\n",
        "\n",
        "    # Append to the overall list\n",
        "    residual_list.append(avg_residual_time)\n",
        "    residual_errors.append(avg_residual_error)\n",
        "\n",
        "    # Store the average residual times and errors for this t value in the corresponding dictionaries\n",
        "    residual_dict[t] = avg_residual_time\n",
        "    error_dict[t] = avg_residual_error"
      ],
      "metadata": {
        "id": "q1wHOWwzSU8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line_styles = ['-', '--', '-.', ':']\n",
        "markers = ['o', 's', '^', 'D']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "for idx, t in enumerate(sampled_indices_list):\n",
        "    x_values = residual_dict[t]\n",
        "    y_values = error_dict[t]\n",
        "    line_style = line_styles[idx % len(line_styles)]\n",
        "    marker = markers[idx % len(markers)]\n",
        "    plt.plot(x_values, y_values, label=f'{t}', linestyle=line_style, marker=marker, linewidth=3)\n",
        "\n",
        "plt.xlabel('Time (in seconds)', fontsize=16)\n",
        "plt.ylabel('Percent of Misclassified Inequalities', fontsize=16)\n",
        "plt.legend(title='Number Sampled Indices', fontsize=14, title_fontsize=16, loc='upper right')\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.grid(True, which='both', axis='both')\n",
        "plt.xlim(left=0)\n",
        "plt.ylim(bottom=0)\n",
        "plt.savefig('time_sampled_indices_q_equals_0.90.png', dpi=300, bbox_inches='tight')  # Save with high resolution\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1K1Hac4uSXxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# $\\beta = 0.20$ Experiments"
      ],
      "metadata": {
        "id": "qFNPp7lNSemG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Synthesize the normally distributed data set"
      ],
      "metadata": {
        "id": "GtrjIg-mWm4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Synthesize 2D data points and normalize them\n",
        "numDataPoints = 50000\n",
        "numFeatures = 100\n",
        "data = np.random.normal(0, 1, size=(numFeatures, numDataPoints))  # Mean=0, S.D. = 1, generates a 100x50000 array\n",
        "# Normalize the data\n",
        "for i in range(data.shape[1]):\n",
        "    data[:, i] = data[:, i] / np.linalg.norm(data[:, i])"
      ],
      "metadata": {
        "id": "U7NgnkiXUj6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# True decision boundary separating the 2 classes of data\n",
        "w_true = np.random.normal(0, 1, size=(numFeatures, 1))\n",
        "\n",
        "# Identify points on either side of the line {x: w_true^T x = 0}\n",
        "labels = np.zeros((1, data.shape[1]))\n",
        "for col_ind in range(data.shape[1]):\n",
        "    if np.dot(data[:, col_ind], w_true) < 0:\n",
        "        labels[0, col_ind] = -1\n",
        "    else:\n",
        "        labels[0, col_ind] = 1\n",
        "\n",
        "correct_labels = labels.copy()\n",
        "# Create a dictionary with the data points and their labels\n",
        "original_data_dict = {}\n",
        "for i in range(data.shape[1]):\n",
        "    key = tuple(data[:, i])\n",
        "    value = labels[0, i]\n",
        "    original_data_dict[key] = value"
      ],
      "metadata": {
        "id": "tBkDzWpsUnjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Mislabel points'''\n",
        "\n",
        "# Number of mislabelled points\n",
        "numMislabelled = 10000\n",
        "\n",
        "fraction_corrupted = numMislabelled / data.shape[1]\n",
        "print(f\"Fraction corrupted: {fraction_corrupted}\")\n",
        "\n",
        "indices = np.where(labels[0] == 1)[0]  # Find indices where labels are 1\n",
        "# Mislabel the first `numMislabelled` points from the positive class\n",
        "mislabelled_indices = indices[:numMislabelled]\n",
        "labels[0, mislabelled_indices] = -1\n",
        "\n",
        "# Now, create a dictionary that includes all data points with their possibly mislabelled labels\n",
        "mislabelled_data_dict = {}\n",
        "\n",
        "# Store the mislabelled data points in the dictionary\n",
        "for i in range(data.shape[1]):\n",
        "    key = tuple(data[:, i])  # Use tuple of the data point as the key\n",
        "    value = labels[0, i]  # Corresponding label (either 1 or -1)\n",
        "    mislabelled_data_dict[key] = value\n",
        "\n",
        "mislabelled_points = {key: value for key, value in mislabelled_data_dict.items() if value == -1}\n",
        "new_labels = np.array(list(original_data_dict.values()))"
      ],
      "metadata": {
        "id": "_MNYP0oJShhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_labels = correct_labels.reshape(-1) # essential line to reshape array\n",
        "labels = labels.reshape(-1) # essential line to reshape array"
      ],
      "metadata": {
        "id": "QYyKA8STa_gR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = correct_labels\n",
        "X_train, y_train = data.T, labels\n",
        "svm_model = LinearSVC(dual=False)\n",
        "svm_model.fit(X_train, y_train)\n",
        "w = svm_model.coef_[0]\n",
        "b = svm_model.intercept_[0]\n",
        "# Manually calculate predictions for X_test using the decision function\n",
        "y_pred = np.sign(np.dot(X_train, w) + b)  # Decision function: w * X + b\n",
        "difference_mask = np.where(correct_labels == labels)  # Only retain the spots where they are equal\n",
        "y_predUncorrupted = y_pred[difference_mask]\n",
        "y_testUncorrupted = y_test[difference_mask]\n",
        "# Now compare these predictions to the true labels (y_test)\n",
        "accuracy = accuracy_score(y_predUncorrupted, y_testUncorrupted)\n",
        "# Print results\n",
        "print(\"Manual predictions:\", y_predUncorrupted)\n",
        "print(\"True labels (y_test):\", y_testUncorrupted)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "dhBPxGR3SyoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function call and error plot"
      ],
      "metadata": {
        "id": "XGVfoQEtS3vT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantile_list = [0.75, 0.8, 0.9, 1]\n",
        "residual_list = []\n",
        "\n",
        "numTrials = 5\n",
        "numIterations = 25000\n",
        "for q in quantile_list:\n",
        "  intermediateResiduals = []\n",
        "  for i in range(numTrials):\n",
        "      x, residuals, _ = perceptronModified(data, labels, q, numDataPoints, numIterations, correct_labels, numMislabelled, numDataPoints)\n",
        "      intermediateResiduals.append(residuals)\n",
        "  intermediateResiduals = np.mean(intermediateResiduals, axis = 0)\n",
        "  residual_list.append(intermediateResiduals)  # Store residuals for each quantile"
      ],
      "metadata": {
        "id": "dnRCcdM9S6ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line_styles = ['-', '--', '-.', ':']\n",
        "plt.figure(figsize=(8, 6))\n",
        "for idx, residuals in enumerate(residual_list):\n",
        "    x = np.arange(len(residuals))\n",
        "    plt.plot(x, residuals, label=f'{quantile_list[idx]}', linestyle=line_styles[idx], linewidth=3)\n",
        "\n",
        "plt.xlim(0, numIterations)\n",
        "plt.yticks(np.arange(0, 110, 10), fontsize=14)\n",
        "plt.xticks(fontsize=14)\n",
        "plt.xlabel('Iterations', fontsize=16)\n",
        "plt.ylabel('Percent of Misclassified Inequalities', fontsize=16)\n",
        "plt.legend(title='Quantile', fontsize=14, title_fontsize=16)  # Increase legend title font size\n",
        "plt.grid(True)\n",
        "plt.savefig('beta_equals_0.20.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z4SVHiGZS9WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampled Indices: Timing them\n"
      ],
      "metadata": {
        "id": "XM2zt16STL2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices_list = [1000, 25000, 50000]"
      ],
      "metadata": {
        "id": "zaN9B4e5TGNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "residual_list = []  # Residual times for each sampled index\n",
        "residual_errors = []  # Residual errors for each sampled index\n",
        "residual_dict = {}  # Dictionary to store residual_list for each t value\n",
        "error_dict = {}  # Dictionary to store residual_errors for each t value\n",
        "q = 1-fraction_corrupted\n",
        "trials = 5\n",
        "numIters = 25000\n",
        "\n",
        "for t in sampled_indices_list:\n",
        "    residual_list_i = []\n",
        "    residual_errors_i = []\n",
        "    for i in range(trials):\n",
        "        x, residuals, residuals_time = perceptronModified(data, labels, q, t, numIters, correct_labels, numMislabelled, numDataPoints)\n",
        "        residual_list_i.append(residuals_time)\n",
        "        residual_errors_i.append(residuals)\n",
        "    # Average the results for this sampled index across the iterations\n",
        "    avg_residual_time = np.mean(residual_list_i, axis=0)\n",
        "    avg_residual_error = np.mean(residual_errors_i, axis=0)\n",
        "\n",
        "    # Append to the overall list\n",
        "    residual_list.append(avg_residual_time)\n",
        "    residual_errors.append(avg_residual_error)\n",
        "\n",
        "    # Store the average residual times and errors for this t value in the corresponding dictionaries\n",
        "    residual_dict[t] = avg_residual_time\n",
        "    error_dict[t] = avg_residual_error"
      ],
      "metadata": {
        "id": "VbZRVKegTPCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line_styles = ['-', '--', '-.', ':']\n",
        "markers = ['o', 's', '^', 'D']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "for idx, t in enumerate(sampled_indices_list):\n",
        "    x_values = residual_dict[t]\n",
        "    y_values = error_dict[t]\n",
        "    line_style = line_styles[idx % len(line_styles)]\n",
        "    marker = markers[idx % len(markers)]\n",
        "    plt.plot(x_values, y_values, label=f'{t}', linestyle=line_style, marker=marker, linewidth=3)\n",
        "\n",
        "plt.xlabel('Time (in seconds)', fontsize=16)\n",
        "plt.ylabel('Percent of Misclassified Inequalities', fontsize=16)\n",
        "plt.legend(title='Number Sampled Indices', fontsize=14, title_fontsize=16, loc='upper right')\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "plt.grid(True, which='both', axis='both')\n",
        "plt.xlim(left=0)\n",
        "plt.ylim(bottom=0)\n",
        "plt.savefig('time_sampled_indices_q_equals_0.80.png', dpi=300, bbox_inches='tight')  # Save with high resolution\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c04WWpIVTSZh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
